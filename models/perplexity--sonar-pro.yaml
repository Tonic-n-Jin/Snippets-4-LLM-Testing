# Perplexity Sonar Pro
# Model defaults for perplexity/sonar-pro
#
# Merge priority: CLI > per-step config > this file > global defaults

display_name: "Sonar Pro"
description: "Advanced web-connected search model for real-time research with superior factuality"
context_length: 127072
output_length: 8192

# Recommended defaults for this model
temperature: 0.2
max_tokens: 4096
top_p: 0.9

# Model capabilities
capabilities:
  - real-time web search
  - multi-step research
  - citation generation
  - factual grounding
  - search domain filtering

# Strengths
strengths:
  - Best factuality (0.858 F-score on SimpleQA benchmark)
  - 2x more citations than standard Sonar
  - 1200 tokens/second (Cerebras inference)
  - Built on Llama 3.3 70B with additional training
  - Three search modes (High/Medium/Low)

# Limitations
limitations:
  - Web search dependent (requires connectivity)
  - Higher latency for complex queries
  - Text-only output

# Prompting notes
notes: |
  Sonar Pro is optimized for research requiring real-time
  information. Best for fact-checking, current events, and
  queries requiring multiple web searches. Use High mode
  for maximum depth, Low mode for speed.
