# Microsoft Phi-4
# Model defaults for microsoft/phi-4
#
# Merge priority: CLI > per-step config > this file > global defaults

display_name: "Phi-4"
description: "Microsoft's 14B small language model specializing in complex reasoning"
context_length: 16384
output_length: 4096

# Recommended defaults for this model
temperature: 0.7
max_tokens: 2048
top_p: 0.95

# Model capabilities
capabilities:
  - complex reasoning
  - math
  - code generation
  - STEM tasks
  - efficient inference

# Model specifications
parameters_total: 14000000000

# Strengths
strengths:
  - Excellent reasoning for 14B size
  - Trained on high-quality synthetic data
  - 21-day training on 1920 H100 GPUs
  - Strong STEM and math performance
  - MIT license (open source)

# Limitations
limitations:
  - Smaller context (16K) than larger models
  - Text-only (no multimodal in base)
  - Limited complex multi-step tasks

# Prompting notes
notes: |
  Phi-4 punches above its weight on reasoning tasks.
  Best for math, STEM, and coding where efficiency
  matters. Use for on-device or cost-sensitive
  deployments requiring solid reasoning.
