# OpenAI o3-mini
# Model defaults for openai/o3-mini
#
# Merge priority: CLI > per-step config > this file > global defaults

display_name: "OpenAI o3-mini"
description: "Advanced reasoning model with chain-of-thought capabilities"
context_length: 200000

# Reasoning models work better with lower temperature
temperature: 0.3
max_tokens: 16384
top_p: 1.0

presence_penalty: 0.0
frequency_penalty: 0.0

notes: "Specialized for complex reasoning - may take longer to respond"
