# AI21 Labs Jamba 1.5 Mini
# Model defaults for ai21/jamba-1.5-mini
#
# Merge priority: CLI > per-step config > this file > global defaults

display_name: "Jamba 1.5 Mini"
description: "AI21's efficient hybrid model with 52B parameters (12B active) and 256K context"
context_length: 256000
output_length: 8192

# Recommended defaults for this model
temperature: 0.7
max_tokens: 4096
top_p: 0.9

# Model capabilities
capabilities:
  - hybrid Mamba-Transformer-MoE architecture
  - long context (256K tokens)
  - single GPU inference (140K tokens)
  - function calling
  - structured output (JSON)

# Model specifications
parameters_total: 52000000000
parameters_active: 12000000000

# Strengths
strengths:
  - 256K context on single GPU
  - Efficient MoE (12B active of 52B total)
  - Maintains quality across full context
  - Lower memory footprint
  - Cost-effective inference

# Limitations
limitations:
  - Smaller than Large variant
  - Text-only (no multimodal)

# Prompting notes
notes: |
  Jamba 1.5 Mini offers efficient long-context processing
  with MoE architecture. Best for resource-constrained
  deployments needing 256K context. Handles 140K tokens
  on a single GPU.
