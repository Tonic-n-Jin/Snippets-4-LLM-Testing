{
  "critical_info": [
    {
      "topic": "design_patterns",
      "example": [
        "Favor dependency injection over hardcoding clients or service objects.",
        "Abstract and decouple metric and logging components for reusability across environments."
      ],
      "detail": "Decoupling components (like metrics, logging, and DB clients) makes systems highly testable, maintainable, and adaptable to different environments (dev, prod) without code changes."
    },
    {
      "topic": "metrics_and_observability",
      "example": [
        "Instrument all states: successes, failures, exception reasons, and latencies.",
        "Standardize metric naming, prefixes, and tagging across all system components.",
        "Expose composite metrics (e.g., SLA streaks) for business insights."
      ],
      "detail": "A unified observability strategy allows for consistent, system-wide dashboards and alerts. Tracking business-level metrics (like SLA streaks) provides actionable insights beyond just system health."
    },
    {
      "topic": "configuration_management",
      "example": [
        "Allow run-time configuration of thresholds, policies, and drift detection parameters.",
        "Parameterize operational behaviors such as warning vs. failure modes."
      ],
      "detail": "Separating configuration from code (e.g., `warn` vs. `fail` policies) empowers operators to tune system behavior in production without requiring a new code deployment, increasing flexibility."
    },
    {
      "topic": "data_validation",
      "example": [
        "Validate all input data for required columns, data types, and schema conformance before processing.",
        "Enforce rigorous contracts with schema tools (Pandera/Pydantic) at all data and API boundaries."
      ],
      "detail": "Enforcing strict, automated data contracts is the most effective way to prevent silent data corruption, which can poison downstream models and analytics. This builds trust in the data platform."
    },
    {
      "topic": "real_world_connectivity",
      "example": [
        "Abstract data sources to support integration with SQL or metadata stores beyond in-memory data."
      ],
      "detail": "Abstracting data sources (e.g., behind a repository pattern) allows code to be tested against in-memory fakes and easily swapped to connect to production data warehouses, ensuring portability."
    },
    {
      "topic": "resilience_and_robustness",
      "example": [
        "Implement retries, backoffs, and connection pools for external dependencies."
      ],
      "detail": "External systems (APIs, DBs) will fail. Building resilience logic (like exponential backoff) directly into clients transforms transient failures from critical errors into non-events, ensuring high availability."
    },
    {
      "topic": "security",
      "example": [
        "Adopt rotating and hashed API keys, enforce rate limits, and use correlation IDs for secure, auditable service calls."
      ],
      "detail": "A multi-layered security approach (e.g., rate limiting, hashed keys, audit logs) is essential for protecting data APIs from abuse, ensuring compliance, and enabling forensics."
    },
    {
      "topic": "correctness_and_safety",
      "example": [
        "Use safe SQL parameterization, input normalization, and complete type-casting for ingest pipelines."
      ],
      "detail": "Ensuring type safety, normalized inputs (like dates), and safe query construction (preventing SQL injection) is fundamental to data integrity and system security."
    },
    {
      "topic": "business_alignment",
      "example": [
        "Measure and expose data-level KPIs such as feature TTLs, schema drift, and staleness, not just system metrics."
      ],
      "detail": "System metrics (like latency) show if the system is *working*. Data-level metrics (like feature staleness) show if the system is providing *business value*. Both are required for a successful data product."
    }
  ]
}
